{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "355d0ea0",
   "metadata": {},
   "source": [
    "# 1. What are Vanilla autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7e15e9",
   "metadata": {},
   "source": [
    "An autoencoder is a neural network model that seeks to learn a compressed representation of an input. An autoencoder is a neural network that is trained to attempt to copy its input to its output. ... Autoencoders are typically trained as part of a broader model that attempts to recreate the input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a085a53",
   "metadata": {},
   "source": [
    "# 2. What are Sparse autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c469532",
   "metadata": {},
   "source": [
    "A Sparse Autoencoder is a type of autoencoder that employs sparsity to achieve an information bottleneck. Specifically the loss function is constructed so that activations are penalized within a layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8250fd",
   "metadata": {},
   "source": [
    "# 3. What are Denoising autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac0b8c9",
   "metadata": {},
   "source": [
    "A Denoising Autoencoder is a modification on the autoencoder to prevent the network learning the identity function. Specifically, if the autoencoder is too big, then it can just learn the data, so the output equals the input, and does not perform any useful representation learning or dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c77f8d",
   "metadata": {},
   "source": [
    "# 4. What are Convolutional autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf3feb3",
   "metadata": {},
   "source": [
    "Convolutional Autoencoder is a variant of Convolutional Neural Networks that are used as the tools for unsupervised learning of convolution filters. They are generally applied in the task of image reconstruction to minimize reconstruction errors by learning the optimal filters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcea12f",
   "metadata": {},
   "source": [
    "# 5. What are Stacked autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db55fbb8",
   "metadata": {},
   "source": [
    "A stacked autoencoder is a neural network consist several layers of sparse autoencoders where output of each hidden layer is connected to the input of the successive hidden layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d45a32b",
   "metadata": {},
   "source": [
    "# 6. Explain how to generate sentences using LSTM autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed86d312",
   "metadata": {},
   "source": [
    "An LSTM Autoencoder is an implementation of an autoencoder for sequence data using an Encoder-Decoder LSTM architecture. Once fit, the encoder part of the model can be used to encode or compress sequence data that in turn may be used in data visualizations or as a feature vector input to a supervised learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b06ed03",
   "metadata": {},
   "source": [
    "# 7. Explain Extractive summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca57428",
   "metadata": {},
   "source": [
    "Extractive methods attempt to summarize articles by identifying the important sentences or phrases from the original text and stitch together portions of the content to produce a condensed version. These extracted sentences are then used to form the summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3935a9d6",
   "metadata": {},
   "source": [
    "# 8. Explain Abstractive summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f378b7e1",
   "metadata": {},
   "source": [
    "Text summarization is the process of extracting salient information from the source text and to present that information to the user in the form of summary. ... Automatic abstractive summarization provides the required solution but it is a challenging task because it requires deeper analysis of text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc9e792",
   "metadata": {},
   "source": [
    "# 9. Explain Beam search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13e3ed5",
   "metadata": {},
   "source": [
    "Beam search uses breadth-first search to build its search tree. At each level of the tree, it generates all successors of the states at the current level, sorting them in increasing order of heuristic cost. However, it only stores a predetermined number, , of best states at each level (called the beam width)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6396a52b",
   "metadata": {},
   "source": [
    "# 10. Explain Length normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b31969d",
   "metadata": {},
   "source": [
    "2,000. 2.9. One simple length normalization formula is to divide the number of occurrences by the length of the document. For example, we can measure the length in pages and divide the number of occurrences (term frequency) by the number of pages as seen in Column 4 above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c2bef2",
   "metadata": {},
   "source": [
    "# 11. Explain Coverage normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655be70c",
   "metadata": {},
   "source": [
    "Normalization is used to scale the data of an attribute so that it falls in a smaller range, such as -1.0 to 1.0 or 0.0 to 1.0. It is generally useful for classification algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b98715",
   "metadata": {},
   "source": [
    "# 12. Explain ROUGE metric evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1882b0a6",
   "metadata": {},
   "source": [
    "ROUGE stands for Recall-Oriented Understudy for Gisting Evaluation. It is essentially a set of metrics for evaluating automatic summarization of texts as well as machine translations. It works by comparing an automatically produced summary or translation against a set of reference summaries"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
