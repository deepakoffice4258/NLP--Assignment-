{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e00187a",
   "metadata": {},
   "source": [
    "# 1. Explain the architecture of BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6619aefe",
   "metadata": {},
   "source": [
    "BERT is basically an Encoder stack of transformer architecture. A transformer architecture is an encoder-decoder network that uses self-attention on the encoder side and attention on the decoder side"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11983c78",
   "metadata": {},
   "source": [
    "# 2. Explain Masked Language Modeling (MLM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca23df4",
   "metadata": {},
   "source": [
    "MLM consists of giving BERT a sentence and optimizing the weights inside BERT to output the same sentence on the other side. So we input a sentence and ask that BERT outputs the same sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72184a20",
   "metadata": {},
   "source": [
    "# 3. Explain Next Sentence Prediction (NSP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54681f0d",
   "metadata": {},
   "source": [
    "Next sentence prediction (NSP) is one-half of the training process behind the BERT model (the other being masked-language modeling â€” MLM). ... So, in this article, we'll cover exactly how we take an unstructured body of text, and use it to fine-tune a BERT model using NSP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5117dc76",
   "metadata": {},
   "source": [
    "# 4. What is Matthews evaluation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbdc470",
   "metadata": {},
   "source": [
    "Matthew's correlation coefficient, also abbreviated as MCC was invented by Brian Matthews in 1975. MCC is a statistical tool used for model evaluation. Its job is to gauge or measure the difference between the predicted values and actual values and is equivalent to chi-square statistics for a 2 x 2 contingency table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43ffd97",
   "metadata": {},
   "source": [
    "# 5. What is Matthews Correlation Coefficient (MCC)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2dad8f",
   "metadata": {},
   "source": [
    "The Matthews correlation coefficient (MCC), instead, is a more reliable statistical rate which produces a high score only if the prediction obtained good results in all of the four confusion matrix categories "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45a1f84",
   "metadata": {},
   "source": [
    "# 6. Explain Semantic Role Labeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f52641",
   "metadata": {},
   "source": [
    "In natural language processing, semantic role labeling (also called shallow semantic parsing or slot-filling) is the process that assigns labels to words or phrases in a sentence that indicates their semantic role in the sentence, such as that of an agent, goal, or result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2e4756",
   "metadata": {},
   "source": [
    "# 7. Why Fine-tuning a BERT model takes less time than pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7581d70",
   "metadata": {},
   "source": [
    "We instead find that fine-tuning primarily affects the top layers of BERT, but with noteworthy variation across tasks. ... In particular, dependency parsing reconfigures most of the model, whereas SQuAD and MNLI appear to involve much shallower processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ef9e3a",
   "metadata": {},
   "source": [
    "# 8. Recognizing Textual Entailment (RTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6fbdf0",
   "metadata": {},
   "source": [
    "Textual entailment recognition is the task of deciding, given two text fragments, whether the meaning of one text is entailed (can be inferred) from another text (see the Instructions tab for the specific operational definition of textual entailment assumed in the challenge)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aff9562",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
