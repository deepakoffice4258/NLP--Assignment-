{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c69fa8b7",
   "metadata": {},
   "source": [
    "# 1. What are Corpora?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a29fe71",
   "metadata": {},
   "source": [
    "Text corpora (singular: text corpus) are large and structured sets of texts, which have been systematically collected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b954d25f",
   "metadata": {},
   "source": [
    "# 2. What are Tokens?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ed04ac",
   "metadata": {},
   "source": [
    "Tokens are the building blocks of Natural Language. Tokenization is a way of separating a piece of text into smaller units called tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f35ef85",
   "metadata": {},
   "source": [
    "# 3. What are Unigrams, Bigrams, Trigrams?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791fa2b7",
   "metadata": {},
   "source": [
    "A 1-gram (or unigram) is a one-word sequence. ... A 2-gram (or bigram) is a two-word sequence of words, like “I love”, “love reading”, or “Analytics Vidhya”. And a 3-gram (or trigram) is a three-word sequence of words like “I love reading”, “about data science” or “on Analytics Vidhya”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838bd5ee",
   "metadata": {},
   "source": [
    "# 4. How to generate n-grams from text?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9e0450",
   "metadata": {},
   "source": [
    "# Creating a function to generate N-Grams.\n",
    "def generate_ngrams(text, WordsToCombine):\n",
    "words = text. split()\n",
    "output = []\n",
    "for i in range(len(words)- WordsToCombine+1):\n",
    "output. append(words[i:i+WordsToCombine])\n",
    "return output.\n",
    "# Calling the function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9fc6c9",
   "metadata": {},
   "source": [
    "# 5. Explain Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8308a069",
   "metadata": {},
   "source": [
    "Lemmatisation (or lemmatization) in linguistics is the process of grouping together the inflected forms of a word so they can be analysed as a single item, identified by the word's lemma, or dictionary form."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073d3b4b",
   "metadata": {},
   "source": [
    "# 6. Explain Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fc7b38",
   "metadata": {},
   "source": [
    "Stemming is the process of reducing a word to its word stem that affixes to suffixes and prefixes or to the roots of words known as a lemma. ... Stemming is also a part of queries and Internet search engines. Recognizing, searching and retrieving more forms of words returns more results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f4ca90",
   "metadata": {},
   "source": [
    "# 7. Explain Part-of-speech (POS) tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45db35d9",
   "metadata": {},
   "source": [
    "It is a process of converting a sentence to forms – list of words, list of tuples (where each tuple is having a form (word, tag)). The tag in case of is a part-of-speech tag, and signifies whether the word is a noun, adjective, verb, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc63b026",
   "metadata": {},
   "source": [
    "# 8. Explain Chunking or shallow parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5fa7ae",
   "metadata": {},
   "source": [
    "Shallow parsing (also chunking or light parsing) is an analysis of a sentence which first identifies constituent parts of sentences (nouns, verbs, adjectives, etc.) and then links them to higher order units that have discrete grammatical meanings (noun groups or phrases, verb groups, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a17169a",
   "metadata": {},
   "source": [
    "# 9. Explain Noun Phrase (NP) chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217c15d5",
   "metadata": {},
   "source": [
    "Chunking is defined as the process of natural language processing used to identify parts of speech and short phrases present in a given sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8579c9",
   "metadata": {},
   "source": [
    "# 10. Explain Named Entity Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3362988",
   "metadata": {},
   "source": [
    "In simple words, Named Entity Recognition is the process of detecting the named entities such as person names, location names, company names, etc from the text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
